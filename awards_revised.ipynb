{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re \n",
    "import string\n",
    "\n",
    "import nltk;\n",
    "from nltk import untag\n",
    "from nltk.collocations import *;\n",
    "from nltk.tokenize import word_tokenize;\n",
    "from nltk.corpus import stopwords;\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/keithpallo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/keithpallo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13 = pd.read_json(\"gg2013.json\")\n",
    "df_14 = pd.read_json(\"../gg2015.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFICIAL_AWARDS_1315 = ['cecil b. demille award', 'best motion picture - drama', 'best performance by an actress in a motion picture - drama', 'best performance by an actor in a motion picture - drama', 'best motion picture - comedy or musical', 'best performance by an actress in a motion picture - comedy or musical', 'best performance by an actor in a motion picture - comedy or musical', 'best animated feature film', 'best foreign language film', 'best performance by an actress in a supporting role in a motion picture', 'best performance by an actor in a supporting role in a motion picture', 'best director - motion picture', 'best screenplay - motion picture', 'best original score - motion picture', 'best original song - motion picture', 'best television series - drama', 'best performance by an actress in a television series - drama', 'best performance by an actor in a television series - drama', 'best television series - comedy or musical', 'best performance by an actress in a television series - comedy or musical', 'best performance by an actor in a television series - comedy or musical', 'best mini-series or motion picture made for television', 'best performance by an actress in a mini-series or motion picture made for television', 'best performance by an actor in a mini-series or motion picture made for television', 'best performance by an actress in a supporting role in a series, mini-series or motion picture made for television', 'best performance by an actor in a supporting role in a series, mini-series or motion picture made for television']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_awards(text):\n",
    "    \" Cleans individual tweet for award search\"\n",
    "    \n",
    "    remove_terms = ['#goldenglobes', 'golden globes', '#goldenglobe', 'golden globe', 'goldenglobes', 'goldenglobe', 'rt', 'golden', 'globe', 'globes']\n",
    "    \n",
    "    text = re.sub(\"(\\s)#\\w+\",\"\",text)    # strips away all hashtags \n",
    "    text = re.sub(\"RT\",\"\",text)          # removes retweet\n",
    "    text = re.sub(\"[^a-zA-Z ]\", '',text) # removes all punctuation but keeps whitespace for tokenization\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = \" \".join([term for term in text if term not in remove_terms]) #remove stop words\n",
    "    \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tags(tweet):\n",
    "    \"\"\"\n",
    "    Performs pos tagging at a tweet level\n",
    "    \"\"\"\n",
    "    \n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_search(tags,chunk_gram,label):\n",
    "    \"\"\n",
    "    \n",
    "    \n",
    "    potentials = \"\"\n",
    "    chunk_parser = nltk.RegexpParser(chunk_gram)\n",
    "    chunked = chunk_parser.parse(tags)\n",
    "    for subtree in chunked.subtrees():\n",
    "        if subtree.label() == label: \n",
    "            raw_list = untag(subtree)\n",
    "            raw_list = [i for i in raw_list if wordnet.synsets(i)]\n",
    "            string = ' '.join(raw_list)\n",
    "            if \"best\" in string[0:6]:\n",
    "                if len(string) >= len(potentials):\n",
    "                    potentials = string\n",
    "                    \n",
    "    if potentials == \"\":\n",
    "        return \"No Chunk\"\n",
    "\n",
    "    return potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df,label):\n",
    "    \n",
    "    data = df.loc[df[label] != \"No Chunk\"]\n",
    "    data.drop(data.columns.difference([label]), 1, inplace=True)\n",
    "    single_list = list(data[label])\n",
    "    freq = FreqDist(single_list)\n",
    "    \n",
    "    return data, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_awards(df):\n",
    "    \"\"\"\n",
    "    Returns a list of strings for all possible awards\n",
    "    \"\"\"\n",
    "    # Shuffle data if necesarry\n",
    "    sample_size = 200000\n",
    "    if len(df['text']) > sample_size:\n",
    "        df = df.sample(n=sample_size)\n",
    "    \n",
    "    # Clean awards, keep best, pos tag\n",
    "    df['text'] = df['text'].apply(lambda x:  clean_awards(x))\n",
    "    df_a = df[df['text'].str.contains(\"best\")]\n",
    "    df_a['tags'] = df_a['text'].apply(lambda x: find_tags(x))\n",
    "    \n",
    "    # Define regex patterns from generalized \n",
    "    regex_pattern_0 = \"P0: {<JJ.><NN.|JJ|VBG><...?>*<NN.>}\"\n",
    "    regex_pattern_1 = \"P1: {<NN.><IN|NN.|IN><...?>*<NN.>}\"\n",
    "    regex_pattern_2 = \"P2: {<RB.><JJ|NN.|VGB><...?>*<NN.|JJ>}\"\n",
    "    \n",
    "    # Search for pos \n",
    "    df_a['chunks_0'] = df_a['tags'].apply(lambda x: pos_search(x,regex_pattern_0,\"P0\"))\n",
    "    df_a['chunks_1'] = df_a['tags'].apply(lambda x: pos_search(x,regex_pattern_1,\"P1\"))\n",
    "    df_a['chunks_2'] = df_a['tags'].apply(lambda x: pos_search(x,regex_pattern_2,\"P2\"))\n",
    "\n",
    "    data_0, freq_0 = filter_df(df_a,\"chunks_0\")\n",
    "    data_1, freq_1 = filter_df(df_a,\"chunks_1\")\n",
    "    data_2, freq_2 = filter_df(df_a,\"chunks_2\")\n",
    "\n",
    "    freq = freq_0 + freq_1 + freq_2\n",
    "    \n",
    "    possible = []\n",
    "\n",
    "    for i in freq.most_common():\n",
    "        if i[1] >= 8: possible.append(i[0])\n",
    "    \n",
    "    return possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible = find_awards(df_13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsample_size = 200000\\nif len(df_13['text']) > sample_size:\\n    df_13 = df_13.sample(n=sample_size)\\n\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_13 = pd.read_json(\"../gg2015.json\")\n",
    "df_13 = pd.DataFrame(df_13)\n",
    "\"\"\"\n",
    "sample_size = 200000\n",
    "if len(df_13['text']) > sample_size:\n",
    "    df_13 = df_13.sample(n=sample_size)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13['text'] = df_13['text'].apply(lambda x:  clean_awards(x))\n",
    "df_a = df_13[df_13['text'].str.contains(\"best\")]\n",
    "df_a['tags'] = df_a['text'].apply(lambda x: find_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_a['chunks_0'] = df_a['tags'].apply(lambda x: pos_search(x,regex_pattern_0,\"P0\"))\n",
    "df_a['chunks_1'] = df_a['tags'].apply(lambda x: pos_search(x,regex_pattern_1,\"P1\"))\n",
    "df_a['chunks_2'] = df_a['tags'].apply(lambda x: pos_search(x,regex_pattern_2,\"P2\"))\n",
    "\n",
    "data_0, freq_0 = filter_df(df_a,\"chunks_0\")\n",
    "data_1, freq_1 = filter_df(df_a,\"chunks_1\")\n",
    "data_2, freq_2 = filter_df(df_a,\"chunks_2\")\n",
    "\n",
    "freq = freq_0 + freq_1 + freq_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best supporting actor in a television series matt',\n",
      " 'best supporting actress in a tv movie series or',\n",
      " 'best dressed men',\n",
      " 'best supporting actor in a motion picture',\n",
      " 'best supporting actor in a series',\n",
      " 'best supporting actress in a series',\n",
      " 'best played girls',\n",
      " 'best awards show monologue in history awards show monologues',\n",
      " 'best actress musical or comedy at big eyes',\n",
      " 'best dressed celebrities',\n",
      " 'best original song at incredible words gentlemen',\n",
      " 'best dresses suits',\n",
      " 'best original song at awards',\n",
      " 'best foreign film at read about russias',\n",
      " 'best actress tv',\n",
      " 'best speeches always come heart not a publicists',\n",
      " 'best dressed stars',\n",
      " 'best supporting actor in a motion picture goes',\n",
      " 'best supporting actor',\n",
      " 'best original song winners',\n",
      " 'best opening monologue jokes',\n",
      " 'best supporting actor goes',\n",
      " 'best original song common',\n",
      " 'best original song',\n",
      " 'best dressed stars at awards naomi watts williams',\n",
      " 'best worst amp wackiest dressed stars',\n",
      " 'best supporting actor in a tv movie series or']\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# pprint(freq.most_common())\n",
    "\n",
    "possible = []\n",
    "\n",
    "for i in freq.most_common():\n",
    "    if i[1] >= 8: possible.append(i[0])\n",
    "        \n",
    "pprint(possible)\n",
    "pprint(len(possible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best supporting actor in a television series matt',\n",
      " 'best supporting actress in a tv movie series or',\n",
      " 'best dressed men',\n",
      " 'best supporting actor in a motion picture',\n",
      " 'best supporting actor in a series',\n",
      " 'best supporting actress in a series',\n",
      " 'best played girls',\n",
      " 'best awards show monologue in history awards show monologues',\n",
      " 'best actress musical or comedy at big eyes',\n",
      " 'best dressed celebrities',\n",
      " 'best original song at incredible words gentlemen',\n",
      " 'best dresses suits',\n",
      " 'best original song at awards',\n",
      " 'best foreign film at read about russias',\n",
      " 'best actress tv',\n",
      " 'best speeches always come heart not a publicists',\n",
      " 'best dressed stars',\n",
      " 'best supporting actor in a motion picture goes',\n",
      " 'best supporting actor',\n",
      " 'best original song winners',\n",
      " 'best opening monologue jokes',\n",
      " 'best supporting actor goes',\n",
      " 'best original song common',\n",
      " 'best original song',\n",
      " 'best dressed stars at awards naomi watts williams',\n",
      " 'best worst amp wackiest dressed stars',\n",
      " 'best supporting actor in a tv movie series or',\n",
      " 'best original song big eyes',\n",
      " 'best red carpet looks',\n",
      " 'best jokes more',\n",
      " 'best supporting actress',\n",
      " 'best moments tonights',\n",
      " 'best or motion picture made television goes',\n",
      " 'best acting nominees',\n",
      " 'best social moments',\n",
      " 'best dressed women',\n",
      " 'best original song glory at awards',\n",
      " 'best supporting actor series movie or',\n",
      " 'best dresses all time',\n",
      " 'best supporting actor in a motion picture is',\n",
      " 'best supporting actor tv',\n",
      " 'best supporting actress boyhood star pays tribute single moms',\n",
      " 'best actress tv drama at affair keep up all winners',\n",
      " 'best dressed celebrities at last nights',\n",
      " 'best supporting actor motion picture',\n",
      " 'best social snaps',\n",
      " 'best original song glory selma',\n",
      " 'best moments fey amp disses amp more biggest night in movies',\n",
      " 'best actress musical or comedy big eyes',\n",
      " 'best moments at cheers',\n",
      " 'best supporting actor in a tv series',\n",
      " 'best actress in a tv comedy or musical winner',\n",
      " 'best supporting tv actress award at goes t',\n",
      " 'best dressed picks',\n",
      " 'best quotes',\n",
      " 'best supporting actor in tv musical or goes',\n",
      " 'best worst amp most moments',\n",
      " 'best actress drama at still',\n",
      " 'best supporting actor in series',\n",
      " 'best original song in a motion picture',\n",
      " 'best dramatic vine goes last words',\n",
      " 'best quotes hear at awards',\n",
      " 'best things humans',\n",
      " 'best foreign language film damning portrayal putins',\n",
      " 'best dresses throughout years',\n",
      " 'best actress musical or comedy at bigeyes',\n",
      " 'best opening monologue jokes at gods',\n",
      " 'best supporting actor at whiplash',\n",
      " 'best jokes so far ew',\n",
      " 'best supporting actor hills calif',\n",
      " 'best dressed list obvious reasons',\n",
      " 'best supporting actor in',\n",
      " 'best dropping george truth bombs',\n",
      " 'best friends amp powerful women',\n",
      " 'best supporting actress in a tv series',\n",
      " 'best nonprofessional comedian goes cc',\n",
      " 'best looking metallic dress but no hair beautiful as always',\n",
      " 'best supporting actress in a',\n",
      " 'best actress musical or comedy at big eyes adams',\n",
      " 'best kids movies',\n",
      " 'best supporting actor in a film karen',\n",
      " 'best actors',\n",
      " 'best moments fey amp',\n",
      " 'best red carpet looks night were on people',\n",
      " 'best moments awards',\n",
      " 'best sounding names',\n",
      " 'best red carpet moments',\n",
      " 'best supporting actor in a motion picture o',\n",
      " 'best jokes at photo',\n",
      " 'best dressed ladies',\n",
      " 'best lines sundays',\n",
      " 'best dressed couples',\n",
      " 'best supporting actor albany times',\n",
      " 'best original song in hunger games',\n",
      " 'best dressed list here comes',\n",
      " 'best original song nominees',\n",
      " 'best supporting actor in motion picture',\n",
      " 'best or motion picture made television fargo',\n",
      " 'best actress drama yes',\n",
      " 'best original song glory so many teary eyes']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(sum(freq.values()))\n",
    "\n",
    "test = []\n",
    "\n",
    "for i in freq.most_common(100):\n",
    "    test.append(i[0])\n",
    "\n",
    "    lt = i[0].split()\n",
    "    string = \"\"\n",
    "    for s in lt:\n",
    "        if wordnet.synsets(s):\n",
    "            string += s\n",
    "            string += \" \"\n",
    "        #print(string)\n",
    "\n",
    "\n",
    "test_2 = []\n",
    "simple_test = [\" \".join(i.split()[:3]) for i in test]\n",
    "\n",
    "pprint(test)\n",
    "\n",
    "test_2.append(test[0])\n",
    "for i in range(1,len(test)):\n",
    "    num_words = test[i].split()\n",
    "    if len(num_words) >= 3:\n",
    "        string = \" \".join(test[i].split()[:3])\n",
    "        #print(string)\n",
    "        if string not in simple_test[0:i] and \"golden globes\" not in test[i]:\n",
    "            test_2.append(test[i])\n",
    "      \n",
    "#pprint(test_2)\n",
    "    \n",
    "    \n",
    "    # Remove [golden globes ]\n",
    "    # Cut after [] ?? \n",
    "    # Condense substrings (if longer than three substring is more frequent, then kick out)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13 = pd.read_json(\"gg2013.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13['text'] = df_13['text'].apply(lambda x:  clean_for_regex(x))\n",
    "\n",
    "\n",
    "def possible_movies(text):\n",
    "    #r1 = re.findall(r\"([A-Z][a-z]+(?=\\s[A-Z])(?:\\s[A-Z][a-z]+)+)\",text)\n",
    "    #print(r1)\n",
    "    #r2 = re.findall(r\"(\\b[A-Z].+?\\b)([a-z].*)(\\b[A-Z].+?\\b)\",text)\n",
    "    #text = ' '.join([term.upper() for term in text if term.lower() in stopwords.words(\"english\")])\n",
    "    #r2 = re.findall(r\"([A-Z][a-z]+(?=\\s[A-Z])(?:\\s[A-Z][a-z]+)+)\",text)\n",
    "    #print(r2)\n",
    "    return r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_regex = list(df_13['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible = []\n",
    "\n",
    "#for i in test_regex:\n",
    "#    possible.append(possible_movies(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_test(dic,freq):\n",
    "    \n",
    "    test = []\n",
    "    \n",
    "    for key in dic.keys():\n",
    "        if key in freq:\n",
    "            test.append([key,freq[key]])\n",
    "        else:\n",
    "            test.append([key,\"Not found\"])\n",
    "        \n",
    "    print(*test,sep='\\n')   \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "def clean_for_regex(text):\n",
    "    text = re.sub(\"(\\s)#\\w+\",\"\",text)    # strips away all hashtags \n",
    "    text = re.sub(\"RT\",\"\",text)\n",
    "    text = re.sub(\"[^a-zA-Z ]\", '',text) # removes all punctuation but keeps whitespace for tokenization \n",
    "    #text = text.lower()\n",
    "    #if \"best\" not in text:\n",
    "    #    return \"\"\n",
    "    \n",
    "    return text \n",
    "    \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
