{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "import math\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "from collections import Counter\n",
    "import statistics as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../gg2015.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'text', 'timestamp_ms', 'user'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['id', 'user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['just had to scramble to find a golden globes stream for my brother. :D',\n",
       "  Timestamp('2015-01-11 22:20:13.011000')],\n",
       " [\"RT @ENews: Show us how you're watching the #GoldenGlobes -- tweet us a pic of your set up, we'll RT our faves! #ERedCarpet\",\n",
       "  Timestamp('2015-01-11 22:25:13.824000')],\n",
       " ['@danaKStew @50ShadesWorldcm @ScarletteDrake Also Red Carpet um 12 &amp; die Show vill. um 1?!',\n",
       "  Timestamp('2015-01-11 22:25:13.869000')],\n",
       " ['RT @lisarinna: When your husband tells you that you Are going to the #GoldenGlobes parties like 5 minutes before you go.......\\nYou just gra…',\n",
       "  Timestamp('2015-01-11 22:25:13.928000')],\n",
       " ['“@goldenglobes: Creating multiple mini Moët Moments on the @GoldenGlobes red carpet… http://t.co/vaLDYqbuD1\\n#MoetMoment” May I have one plz?',\n",
       "  Timestamp('2015-01-11 22:25:14.067000')]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestampToUnix(t):\n",
    "    return time.mktime(t.timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('english.txt', 'r')\n",
    "stop_words = f.read().splitlines()\n",
    "#print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFICIAL_AWARDS_1315 = ['cecil b. demille award', \n",
    "                        'best motion picture - drama', \n",
    "                        'best performance by an actress in a motion picture - drama', \n",
    "                        'best performance by an actor in a motion picture - drama', \n",
    "                        'best motion picture - comedy or musical', \n",
    "                        'best performance by an actress in a motion picture - comedy or musical', \n",
    "                        'best performance by an actor in a motion picture - comedy or musical', \n",
    "                        'best animated feature film', 'best foreign language film', \n",
    "                        'best performance by an actress in a supporting role in a motion picture', \n",
    "                        'best performance by an actor in a supporting role in a motion picture', \n",
    "                        'best director - motion picture', 'best screenplay - motion picture', \n",
    "                        'best original score - motion picture', \n",
    "                        'best original song - motion picture', \n",
    "                        'best television series - drama', \n",
    "                        'best performance by an actress in a television series - drama', \n",
    "                        'best performance by an actor in a television series - drama', \n",
    "                        'best television series - comedy or musical', \n",
    "                        'best performance by an actress in a television series - comedy or musical', \n",
    "                        'best performance by an actor in a television series - comedy or musical', \n",
    "                        'best mini-series or motion picture made for television', \n",
    "                        'best performance by an actress in a mini-series or motion picture made for television', \n",
    "                        'best performance by an actor in a mini-series or motion picture made for television', \n",
    "                        'best performance by an actress in a supporting role in a series, mini-series or motion picture made for television', \n",
    "                        'best performance by an actor in a supporting role in a series, mini-series or motion picture made for television']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseAward(award):\n",
    "    award = re.split('\\W+', award)\n",
    "    award = [i for i in award if i not in stop_words]\n",
    "    return award"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAwardCategories():\n",
    "    category_dict = dict()\n",
    "    for a in OFFICIAL_AWARDS_1315:\n",
    "        terms = parseAward(a)\n",
    "        category_dict[a] = terms\n",
    "        \n",
    "    return category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getTweetsForAward(data, list1):\n",
    "    synonyms = {\n",
    "        'motion' : ['motion picture', 'motion', 'picture', 'movie'],\n",
    "        'picture' : ['motion picture', 'motion', 'picture', 'movie'],\n",
    "        'television' : ['television', 'tv'],\n",
    "        'mini' : ['mini-series', 'mini', 'series', 'miniseries'],\n",
    "        'series' : ['mini-series', 'mini', 'series', 'miniseries']\n",
    "    }\n",
    "    \n",
    "    #result = pd.DataFrame(columns={'text', 'timestamp_ms'})\n",
    "    time = []\n",
    "    #count = 0\n",
    "    \n",
    "    list1 = [i for i in list1 if i != 'performance' and i != 'role']\n",
    "\n",
    "    for tweet in df['text']:\n",
    "        cond = True\n",
    "        for i in list1:\n",
    "            if i in synonyms:\n",
    "                if all(j not in tweet.lower() for j in synonyms[i]):\n",
    "                    cond = False\n",
    "            elif i not in tweet.lower():\n",
    "                cond = False\n",
    "        if cond:\n",
    "            #result = result.append(data.loc[data.text == tweet, ['text', 'timestamp_ms']])\n",
    "            time = time.append(timestampToUnix(data['timestamp_ms'][data.text == tweet]))\n",
    "            #count += 1\n",
    "            \n",
    "    #df = pd.concat(result)\n",
    "\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweetsInTimeRange(time):\n",
    "    #df['unixtime'] = df['timestamp_ms'].apply(lambda x:  timestampToUnix(x))\n",
    "    \n",
    "    \n",
    "    mean = st.mean(time)\n",
    "    stdev = st.stdev(time)\n",
    "    starttime = mean - (stdev*1)\n",
    "    endtime = mean + (stdev*1)\n",
    "    \n",
    "    starttime = datetime.datetime.fromtimestamp(starttime).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    endtime = datetime.datetime.fromtimestamp(endtime).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    mask = (df['timestamp_ms'] >= starttime) & (df['timestamp_ms'] <= endtime)\n",
    "    df = df.loc[mask]\n",
    "    print(len(df))\n",
    "    return df['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTweetsInTimeRange2(df):\n",
    "    starttime = df['timestamp_ms'].min()\n",
    "    endtime = df['timestamp_ms'].max()\n",
    "    mask = (data['timestamp_ms'] >= starttime) & (data['timestamp_ms'] <= endtime)\n",
    "    df = data.loc[mask]\n",
    "    print(len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter0(data, word):\n",
    "    result = []\n",
    "    for tweet in data['text']:\n",
    "        if word in tweet:\n",
    "            result.append(tweet)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPresenters(data, list1):\n",
    "    #print(data[0])\n",
    "    result = []\n",
    "    \n",
    "    tt = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=True)\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "    # strip stopwords, punctuation \n",
    "    #punctuation = list(string.punctuation)\n",
    "    remove_terms = ['#goldenglobes', 'golden globes', '#goldenglobe', 'golden globe', 'goldenglobes', 'goldenglobe', 'rt', 'golden', 'globe', 'globes']    \n",
    "    stop = remove_terms + list1\n",
    "    \n",
    "    for tweet in data:\n",
    "        #print(tweet)\n",
    "        tweet = re.sub(\"\\d+\", \"\", tweet) #strip nums\n",
    "        tweet = re.sub(r'http\\S+', '', tweet) #strip urls\n",
    "        tweet = re.sub(r'#\\S+', '', tweet) #strip hashtags\n",
    "        #tweet = re.sub(r'[^\\w\\s]', '', tweet) #strip non-alphanumeric characters\n",
    "        tweet = tweet.translate(translator)\n",
    "        tweet = tweet.split() #tokenize\n",
    "        tweet = [term for term in tweet if term.lower() not in stop_words] #remove stop words\n",
    "        for i in stop:\n",
    "            for j in tweet:\n",
    "                if i.lower() in j.lower():\n",
    "                    tweet.remove(j)\n",
    "        result.append(tweet)\n",
    "        \n",
    "    #print(result[:20])\n",
    "        \n",
    "    grams = [];\n",
    "\n",
    "    for tweet in result:\n",
    "        if tweet:\n",
    "            gram = list(nltk.everygrams(tweet, 2, 3))\n",
    "            #print(bigram[:10])\n",
    "            for g in gram:\n",
    "                if len(g) == 2:\n",
    "                    if bool(re.match(r'\\b[A-Z][a-z]+\\b', g[0])) and bool(re.match(r'\\b[A-Z][a-z]+\\b', g[1])):\n",
    "                        grams.append(g)\n",
    "                else:\n",
    "                    if bool(re.match(r'\\b[A-Z][a-z]+\\b', g[0])) and bool(re.match(r'\\b[A-Z][a-z]+\\b', g[1])) and bool(re.match(r'\\b[A-Z][a-z]+\\b', g[2])):\n",
    "                        grams.append(g)\n",
    "  \n",
    "    fdist = nltk.FreqDist(grams)\n",
    "    #print(fdist)\n",
    "    \n",
    "    try:\n",
    "        temp = fdist.most_common(1)[0][0]\n",
    "        name = ' '.join(temp)\n",
    "    except:\n",
    "        name = \"nothing here\"\n",
    "    \n",
    "    return fdist.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mktime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-8ed34137d26c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maward\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mOFFICIAL_AWARDS_1315\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTweetsForAward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTweetsInTimeRange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpresenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractPresenters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-7e39459d0a2f>\u001b[0m in \u001b[0;36mgetTweetsForAward\u001b[0;34m(data, list1)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m#result = result.append(data.loc[data.text == tweet, ['text', 'timestamp_ms']])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestampToUnix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp_ms'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;31m#count += 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9af03b48414e>\u001b[0m in \u001b[0;36mtimestampToUnix\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtimestampToUnix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmktime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimetuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'mktime'"
     ]
    }
   ],
   "source": [
    "category_dict = getAwardCategories()\n",
    "\n",
    "for award in OFFICIAL_AWARDS_1315:    \n",
    "    time = getTweetsForAward(df, category_dict[award])\n",
    "    tweets = getTweetsInTimeRange(time)\n",
    "    presenters = extractPresenters(tweets, category_dict[award])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for award in OFFICIAL_AWARDS_1315:\n",
    "    print(tweets[award][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPresenters(tweets, category_dict):\n",
    "        #df = getTweetsInTimeRange(df)\n",
    "        #print(df[:5], len(df))\n",
    "        #stopwords = category_dict[award] + ['Jessica', 'Chastain', 'Marion', 'Cotillard', 'Helen', 'Mirren', 'Naomi', 'Watts', 'Rachel', 'Weisz']\n",
    "        presenters = {}\n",
    "        for award in OFFICIAL_AWARDS_1315:\n",
    "            results = filter0(tweets[award], 'present')\n",
    "        #print(results[:5])\n",
    "            presenters[award] = extractPresenters(results, category_dict[award])\n",
    "        #print(award, presenters)\n",
    "        return presenters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "getPresenters(tweets, category_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
