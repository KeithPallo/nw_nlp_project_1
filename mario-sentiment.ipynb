{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "import operator\n",
    "import string\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Data is a list of tweets\n",
    "def getBestDressed(data, kb):\n",
    "    \n",
    "    result = []\n",
    "       \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    remove_terms = ['#goldenglobes', 'golden globes', '#goldenglobe', 'golden globe', 'goldenglobes', 'goldenglobe', 'golden', 'globe', 'globes']\n",
    "    stop = remove_terms\n",
    "    include_terms = ['dress', 'fashion', 'red', 'carpet', 'haute couture', 'gown', 'design']\n",
    "    \n",
    "    for tweet in data:\n",
    "        \n",
    "        tweet = re.sub(\"\\d+\", \"\", tweet)       #strip nums\n",
    "        tweet = re.sub(r'http\\S+', '', tweet)  #strip urls\n",
    "        tweet = re.sub(r'#\\S+', '', tweet)     #strip hashtags\n",
    "        tweet = tweet.translate(translator)    #strip non-alphanumeric characters\n",
    "\n",
    "        for i in stop:\n",
    "            for j in tweet:\n",
    "                if i.lower() in j.lower():\n",
    "                    tweet.remove(j)\n",
    "        \n",
    "        if any(term in tweet for term in include_terms) and 'suit' not in tweet:\n",
    "            result.append(tweet)\n",
    "    \n",
    "    \n",
    "    # extract people and put in dictionary with compound scores\n",
    "    sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "    score_dict = {}\n",
    "    best_dressed_dict = {}\n",
    "    worst_dressed_dict = {}\n",
    "\n",
    "    for tweet in result:\n",
    "        all_scores = sentiment_analyzer.polarity_scores(tweet)\n",
    "        for k in sorted(all_scores):\n",
    "            if k == 'compound':\n",
    "                useful_score = all_scores[k]\n",
    "\n",
    "        if tweet:\n",
    "            # Get all possible bigrams & trigrams in a tweet\n",
    "            gram = list(nltk.everygrams(tweet.split(), 2, 3))\n",
    "\n",
    "            # Filter through and append to list for tweet\n",
    "            for g in gram:\n",
    "                if len(g) == 2:\n",
    "                    if bool(re.match(r'\\b[A-Z][a-z]+\\b', g[0])) and bool(re.match(r'\\b[A-Z][a-z]+\\b', g[1])):\n",
    "                        name = ' '.join(g).lower()\n",
    "                        if useful_score > 0:\n",
    "                            if name in best_dressed_dict:\n",
    "                                best_dressed_dict[name] += useful_score\n",
    "                            else:\n",
    "                                best_dressed_dict[name] = useful_score\n",
    "                        if useful_score < 0:\n",
    "                            if name in worst_dressed_dict:\n",
    "                                worst_dressed_dict[name] += useful_score\n",
    "                            else:\n",
    "                                worst_dressed_dict[name] = useful_score\n",
    "                else:\n",
    "                    if bool(re.match(r'\\b[A-Z][a-z]+\\b', g[0])) and bool(re.match(r'\\b[A-Z][a-z]+\\b', g[1])) and bool(re.match(r'\\b[A-Z][a-z]+\\b', g[2])):\n",
    "                        name = ' '.join(g).lower()\n",
    "                        if useful_score > 0:\n",
    "                            if name in best_dressed_dict:\n",
    "                                best_dressed_dict[name] += useful_score\n",
    "                            else:\n",
    "                                best_dressed_dict[name] = useful_score\n",
    "                        if useful_score < 0:\n",
    "                            if name in worst_dressed_dict:\n",
    "                                worst_dressed_dict[name] += useful_score\n",
    "                            else:\n",
    "                                worst_dressed_dict[name] = useful_score\n",
    "        \n",
    "        \n",
    "    # look in kb for matches     \n",
    "    final_dict = {}\n",
    "    for best, worst in zip(best_dressed_dict, worst_dressed_dict):\n",
    "        if best.lower() in kb:\n",
    "            final_dict[best] = best_dressed_dict[best]\n",
    "        if worst.lower() in kb:\n",
    "            final_dict[worst] = worst_dressed_dict[worst]\n",
    "            \n",
    "\n",
    "    # get key with max value\n",
    "    best_dressed = []\n",
    "    worst_dressed = []\n",
    "    \n",
    "    while len(best_dressed) < 6:\n",
    "        best_person = max(final_dict.items(), key=lambda k: k[1])[0]\n",
    "        worst_person = min(final_dict.items(), key=lambda k: k[1])[0]\n",
    "        best_dressed.append(best_person)\n",
    "        worst_dressed.append(worst_person)\n",
    "        del final_dict[best_person]\n",
    "        del final_dict[worst_person]\n",
    "    \n",
    "    return best_dressed, worst_dressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
