{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "import math\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('gg2013.json')\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return cleaned Tweet as string\n",
    "# remove stopwords, user handles, punctuation, urls\n",
    "\n",
    "def cleanTweets(tweet):\n",
    "    tt = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=True)\n",
    "\n",
    "    punctuation = list(string.punctuation)\n",
    "    \n",
    "    # strip stopwords, punctuation, url components \n",
    "    stop = stopwords.words('english') + punctuation + ['t.co', 'http', 'https', '...', '..', ':\\\\', 'RT', '#']\n",
    "\n",
    "    strip_nums = re.sub(\"\\d+\", \"\", tweet)\n",
    "    tokenized = tt.tokenize(strip_nums)\n",
    "    terms_stop = [term for term in tokenized if term not in stop]\n",
    "    cleaned = [term for term in terms_stop]\n",
    "    cleaned = ' '.join(cleaned)\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter0(data):\n",
    "    results = []\n",
    "    \n",
    "    for tweet in data['text']:\n",
    "        if 'best' in tweet.lower():\n",
    "            results.append(tweet)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def filter0(data):\n",
    "    results = []\n",
    "    \n",
    "    win = ['best', 'win', 'winner', 'winners', 'winning', 'won', 'wins', 'award', 'awards']\n",
    "    \n",
    "    for tweet in data['text']:\n",
    "        if any(term in tweet.lower() for term in win):\n",
    "            results.append(tweet)\n",
    "            \n",
    "    return results\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f0 = filter0(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18694\n"
     ]
    }
   ],
   "source": [
    "print(len(f0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter1(data):\n",
    "    movie_results = []\n",
    "    tv_results = []\n",
    "    \n",
    "    movie = ['motion picture', 'movie', 'movies']\n",
    "    tv = ['tv', 'television']\n",
    "\n",
    "    \n",
    "    for tweet in data:\n",
    "        if any(term in tweet.lower() for term in movie):\n",
    "            movie_results.append(tweet)\n",
    "        elif any(term in tweet.lower() for term in tv):\n",
    "            tv_results.append(tweet)\n",
    "            \n",
    "    return movie_results, tv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_movie, f1_tv = filter1(f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5784\n"
     ]
    }
   ],
   "source": [
    "print(len(f1_movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317\n"
     ]
    }
   ],
   "source": [
    "print(len(f1_tv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter2(data):\n",
    "    actor_results = []\n",
    "    media_results = []\n",
    "    \n",
    "    actor = ['actor', 'actress', 'actors', 'actresses']\n",
    "\n",
    "    \n",
    "    for tweet in data:\n",
    "        if any(term in tweet.lower() for term in actor):\n",
    "            actor_results.append(tweet)\n",
    "        else:\n",
    "            media_results.append(tweet)\n",
    "            \n",
    "    return actor_results, media_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_movie_actor, f2_movie_media = filter2(f1_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173\n"
     ]
    }
   ],
   "source": [
    "print(len(f2_movie_actor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2611\n"
     ]
    }
   ],
   "source": [
    "print(len(f2_movie_media))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_tv_actor, f2_tv_media = filter2(f1_tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1342\n",
      "975\n"
     ]
    }
   ],
   "source": [
    "print(len(f2_tv_actor))\n",
    "print(len(f2_tv_media))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter3(data):\n",
    "    actor_results = []\n",
    "    media_results = []\n",
    "    \n",
    "    actor = ['actor', 'actress', 'actors', 'actresses']\n",
    "\n",
    "    \n",
    "    for tweet in data:\n",
    "        if any(term in tweet.lower() for term in actor):\n",
    "            actor_results.append(tweet)\n",
    "        else:\n",
    "            media_results.append(tweet)\n",
    "            \n",
    "    return actor_results, media_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(data, list1, list2):\n",
    "    result1 = []\n",
    "    result2 = []\n",
    "    \n",
    "    for tweet in data:\n",
    "        if any(term in tweet.lower() for term in list1):\n",
    "            result1.append(tweet)\n",
    "        elif any(term in tweet.lower() for term in list2):\n",
    "            result2.append(tweet)\n",
    "            \n",
    "    return result1, result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
