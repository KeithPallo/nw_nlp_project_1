{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re \n",
    "\n",
    "import nltk;\n",
    "from nltk.collocations import *;\n",
    "from nltk.tokenize import word_tokenize;\n",
    "from nltk.corpus import stopwords;\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ikhlas/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13 = pd.read_json(\"gg2013.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13 = pd.DataFrame(df_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GG_OFFICIAL_AWARDS = [\n",
    "    #Motion picture awards\n",
    "    'Best Motion Picture - Drama', #good\n",
    "    'Best Motion Picture - Musical or Comedy',  #good\n",
    "    'Best Motion Picture - Foreign Language', #good\n",
    "    'Best Motion Picture - Animated', #good\n",
    "    'Best Director - Motion Picture', #good\n",
    "    'Best Actor - Motion Picture Drama',\n",
    "    'Best Actor - Motion Picture Musical or Comedy',\n",
    "    'Best Actress - Motion Picture Drama',\n",
    "    'Best Actress - Motion Picture Musical or Comedy',\n",
    "    'Best Supporting Actor - Motion Picture',\n",
    "    'Best Supporting Actress - Motion Picture',\n",
    "    'Best Screenplay - Motion Picture',\n",
    "    'Best Original Score - Motion Picture',\n",
    "    'Best Original Song - Motion Picture',\n",
    "    '2 Awards for Lifetime Achievement in Motion Pictures',\n",
    "    #Television awards\n",
    "    'Best Television Series - Drama',\n",
    "    'Best Television Series - Musical or Comedy',\n",
    "    'Best Miniseries or Television Film',\n",
    "    'Best Actor - Television Series Drama',\n",
    "    'Best Actor - Television Series Musical or Comedy',\n",
    "    'Best Actor - Miniseries or Television Film',\n",
    "    'Best Actress - Television Series Drama',\n",
    "    'Best Actress - Television Series Musical or Comedy',\n",
    "    'Best Actress - Miniseries or Television Film',\n",
    "    'Best Supporting Actor - Series, Miniseries or Television Film',\n",
    "    'Best Supporting Actress - Series, Miniseries or Television Film',\n",
    "    'Carol Burnett Award for Achievement in Television'\n",
    "]\n",
    "\n",
    "# ['cecil b. demille award', \n",
    "# 'best motion picture - drama', \n",
    "# 'best performance by an actress in a motion picture - drama', \n",
    "# 'best performance by an actor in a motion picture - drama', \n",
    "# 'best motion picture - comedy or musical', \n",
    "#  'best performance by an actress in a motion picture - comedy or musical', \n",
    "#  'best performance by an actor in a motion picture - comedy or musical', \n",
    "#  'best animated feature film', 'best foreign language film', \n",
    "#  'best performance by an actress in a supporting role in a motion picture', \n",
    "#  'best performance by an actor in a supporting role in a motion picture', \n",
    "#  'best director - motion picture', 'best screenplay - motion picture', \n",
    "#  'best original score - motion picture', 'best original song - motion picture', \n",
    "#  'best television series - drama', 'best performance by an actress in a television series - drama', \n",
    "#  'best performance by an actor in a television series - drama', 'best television series - comedy or musical', \n",
    "#  'best performance by an actress in a television series - comedy or musical', \n",
    "#  'best performance by an actor in a television series - comedy or musical', \n",
    "#  'best mini-series or motion picture made for television', \n",
    "#  'best performance by an actress in a mini-series or motion picture made for television', \n",
    "#  'best performance by an actor in a mini-series or motion picture made for television', \n",
    "#  'best performance by an actress in a supporting role in a series, mini-series or motion picture made for television',\n",
    "#  'best performance by an actor in a supporting role in a series, mini-series or motion picture made for television']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_OFFICIAL_AWARDS = [\n",
    "    #Pop\n",
    "    'Best Pop Solo Performance',\n",
    "    'Best Pop Duo/Group Performance',\n",
    "    'Best Pop Vocal Album',\n",
    "    'Best Traditional Pop Vocal Album',\n",
    "    #Dance/Electronic\n",
    "    'Best Dance Recording',\n",
    "    'Best Dance/Electronic Album',\n",
    "    #Contemporary Instrumental\n",
    "    'Best Contemporary Instrumental Album',\n",
    "    #Rock\n",
    "    'Best Rock Performance',\n",
    "    'Best Metal Performance',\n",
    "    'Best Rock Song',\n",
    "    'Best Rock Album',\n",
    "    #Alternative\n",
    "    'Best Alternative Music Album',\n",
    "    #R&B\n",
    "    'Best R&B Performance',\n",
    "    'Best Traditional R&B Performance',\n",
    "    'Best R&B Song',\n",
    "    'Best Urban Contemporary Album',\n",
    "    'Best R&B Album',\n",
    "    #Rap\n",
    "    'Best Rap Performance',\n",
    "    'Best Rap/Sung Performance',\n",
    "    'Best Rap Song',\n",
    "    'Best Rap Album',\n",
    "    #Country\n",
    "    'Best Country Solo Performance',\n",
    "    'Best Country Duo/Group Performance',\n",
    "    'Best Country Song',\n",
    "    'Best Country Album',\n",
    "    #New Age\n",
    "    'Best New Age Album',\n",
    "    #Jazz\n",
    "    'Best Improvised Jazz Solo',\n",
    "    'Best Jazz Vocal Album',\n",
    "    'Best Jazz Instrumental Album',\n",
    "    'Best Large Jazz Ensemble Album',\n",
    "    'Best Latin Jazz Album',\n",
    "    #Gospel/Contemporary Christian Music\n",
    "    'Best Gospel Performance/Song',\n",
    "    'Best Contemporary Christian Music Performance/Song',\n",
    "    'Best Gospel Album',\n",
    "    'Best Contemporary Christian Music Album',\n",
    "    'Best Roots Gospel Album',\n",
    "    #Latin\n",
    "    'Best Latin Pop Album',\n",
    "    'Best Latin Rock, Urban or Alternative Album',\n",
    "    'Best Regional Mexican Music Album (including Tejano)',\n",
    "    'Best Tropical Latin Album',\n",
    "    #American Roots\n",
    "    'Best American Roots Performance',\n",
    "    'Best American Roots Song',\n",
    "    'Best Americana Album',\n",
    "    'Best Bluegrass Album',\n",
    "    'Best Contemporary Blues Album',\n",
    "    'Best Traditional Blues Album',\n",
    "    'Best Folk Album',\n",
    "    'Best Regional Roots Music Album',\n",
    "    #Reggae\n",
    "    'Best Reggae Album',\n",
    "    #World Music\n",
    "    'Best World Music Album',\n",
    "    #Children's\n",
    "    \"Best Children's Album\",\n",
    "    #Spoken Word\n",
    "    'Best Spoken Word Album (Includes Poetry, Audio Books & Storytelling)',\n",
    "    #Comedy\n",
    "    'Best Comedy Album',\n",
    "    #Musical Theatre\n",
    "    'Best Musical Theater Album',\n",
    "    #Music for Visual Media\n",
    "    'Best Compilation Soundtrack for Visual Media',\n",
    "    'Best Score Soundtrack Album for Visual Media',\n",
    "    'Best Song Written for Visual Media',\n",
    "    #Composing\n",
    "    'Best Instrumental Composition',\n",
    "    # Arranging\n",
    "    'Best Arrangement, Instrumental or A Cappella',\n",
    "    'Best Arrangement, Instrumental and Vocals',\n",
    "    # Packaging\n",
    "    'Best Recording Package',\n",
    "    'Best Boxed or Special Limited Edition Package',\n",
    "    # Notes\n",
    "    'Best Album Notes',\n",
    "    # Historical\n",
    "    'Best Historical Album',\n",
    "    # Engineered Album\n",
    "    'Best Engineered Album, Non-Classical',\n",
    "    'Best Engineered Album, Classical',\n",
    "    # Producer\n",
    "    'Producer of the Year, Non-Classical',\n",
    "    'Producer of the Year, Classical',\n",
    "    # Remixer\n",
    "    'Best Remixed Recording, Non-Classical',\n",
    "    'Surround Sound',\n",
    "    'Best Inmersive Audio Album',\n",
    "    # Classical\n",
    "    'Best Orchestral Performance',\n",
    "    'Best Opera Recording',\n",
    "    'Best Choral Performance',\n",
    "    'Best Chamber Music/Small Ensemble Performance',\n",
    "    'Best Classical Instrumental Solo',\n",
    "    'Best Classical Vocal Solo (previously including albums and tracks)',\n",
    "    'Best Classical Compendium',\n",
    "    'Best Contemporary Classical Composition',\n",
    "    # Music Video/Film\n",
    "    'Best Music Video',\n",
    "    'Best Music Film'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_OFFICIAL_AWARDS = [\n",
    "    # Current Categories\n",
    "    'Best Picture', #good\n",
    "    'Best Directing', #good\n",
    "    'Best Actor In A Leading Role', #good\n",
    "    'Best Actress In A Leading Role', #good\n",
    "    'Best Actor In A Supporting Role', #good\n",
    "    'Best Actress In A Supporting Role', #good\n",
    "    'Best Animated Feature Film', #good\n",
    "    'Best Short Film (Animated)', #good\n",
    "    'Best Cinematography', #good\n",
    "    'Best Costume Design', #good\n",
    "    'Best Documentary Feature', #good\n",
    "    'Best Documentary (Short Subject)', #good\n",
    "    'Best Film Editing', #good\n",
    "    'Best Foreign Language Film', #good\n",
    "    'Best Short Film (Live Action)', #good\n",
    "    'Best Makeup and Hairstyling', #good\n",
    "    'Best Music (Original Score)', #good\n",
    "    'Best Music (Original Song)', #good\n",
    "    'Best Production Design', #good\n",
    "    'Best Sound Editing', #good\n",
    "    'Best Sound Mixing', #good\n",
    "    'Best Visual Effects', #good\n",
    "    'Best Writing (Adapted Screenplay)', #good\n",
    "    'Best Writing (Original Screenplay)' #good\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_OFFICIAL_AWARDS = [\n",
    "    #Primetime Emmy\n",
    "    # Programs\n",
    "    'Outstanding Comedy Series',\n",
    "    'Outstanding Drama Series',\n",
    "    'Outstanding Limited Series',\n",
    "    'Outstanding Competition Program',\n",
    "    'Outstanding Television Movie',\n",
    "    'Outstanding Variety Sketch Series',\n",
    "    'Outstanding Variety Talk Series',\n",
    "    # Directing\n",
    "    'Outstanding Directing for a Comedy Series',\n",
    "    'Outstanding Directing for a Drama Series',\n",
    "    'Outstanding Directing for a Limited Series, Movie, or Dramatic Special',\n",
    "    'Outstanding Directing for a Variety Series',\n",
    "    # Writing\n",
    "    'Outstanding Writing for a Comedy Series',\n",
    "    'Outstanding Writing for a Drama Series',\n",
    "    'Outstanding Writing for a Limited Series, Movie, or Dramatic Special',\n",
    "    'Outstanding Writing for a Variety Series',\n",
    "    # Acting\n",
    "    'Lead Actor',\n",
    "    'Outstanding Lead Actor in a Comedy Series',\n",
    "    'Outstanding Lead Actor in a Drama Series',\n",
    "    'Outstanding Lead Actor in a Limited Series or Movie',\n",
    "    # Lead Actress\n",
    "    'Outstanding Lead Actress in a Comedy Series',\n",
    "    'Outstanding Lead Actress in a Drama Series',\n",
    "    'Outstanding Lead Actress in a Limited Series or Movie',\n",
    "    # Supporting Actor\n",
    "    'Outstanding Supporting Actor in a Comedy Series',\n",
    "    'Outstanding Supporting Actor in a Drama Series',\n",
    "    'Outstanding Supporting Actor in a Limited Series or Movie',\n",
    "    # Supporting Actress\n",
    "    'Outstanding Supporting Actress in a Comedy Series',\n",
    "    'Outstanding Supporting Actress in a Drama Series',\n",
    "    'Outstanding Supporting Actress in a Limited Series or Movie'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN_OFFICIAL_AWARDS = [\n",
    "    #Performance categories\n",
    "    'Best Performance by a Leading Actor in a Play',\n",
    "    'Best Performance by a Featured Actor in a Play',\n",
    "    'Best Performance by a Leading Actor in a Musical',\n",
    "    'Best Performance by a Featured Actor in a Musical',\n",
    "    'Best Performance by a Leading Actress in a Play',\n",
    "    'Best Performance by a Featured Actress in a Play',\n",
    "    'Best Performance by a Leading Actress in a Musical',\n",
    "    'Best Performance by a Featured Actress in a Musical',\n",
    "    #Show and technical categories\n",
    "    'Best Musical',\n",
    "    'Best Revival of a Musical',\n",
    "    'Best Direction of a Musical',\n",
    "    'Best Book of a Musical',\n",
    "    'Best Original Score',\n",
    "    'Best Orchestrations',\n",
    "    'Best Choreography',\n",
    "    'Best Scenic Design in a Musical',\n",
    "    'Best Costume Design in a Musical',\n",
    "    'Best Lighting Design in a Musical',\n",
    "    'Best Sound Design of a Musical',\n",
    "    'Best Play',\n",
    "    'Best Revival of a Play',\n",
    "    'Best Direction of a Play',\n",
    "    'Best Scenic Design in a Play',\n",
    "    'Best Costume Design in a Play',\n",
    "    'Best Lighting Design in a Play',\n",
    "    'Best Sound Design of a Play'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_awards = list(set(GG_OFFICIAL_AWARDS + GM_OFFICIAL_AWARDS + AA_OFFICIAL_AWARDS + EM_OFFICIAL_AWARDS + TN_OFFICIAL_AWARDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_awards = [re.sub(\"[^a-zA-Z0-9]+\", ' ',i) for i in total_awards];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_structure = []\n",
    "\n",
    "for sentence in clean_awards:\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(tokenized_text)\n",
    "    pos_structure.append([i[1] for i in tagged])\n",
    "\n",
    "#for i in range(0,len(clean_awards)):\n",
    "#    pos_structure[i].append(clean_awards[i])\n",
    "    \n",
    "#award_dict = {}\n",
    "\n",
    "#for award in pos_structure:\n",
    "#    award_dict[award[-1]] = award[:-1]\n",
    "    \n",
    "# pos_structure.sort()\n",
    "# print(*pos_structure,sep='\\n')\n",
    "\n",
    "# print(award_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "award_dict = defaultdict(int)\n",
    "for pos in pos_structure:\n",
    "    award_dict[str(pos)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>,\n",
      "            {\"['JJ', 'NN']\": 1,\n",
      "             \"['JJS', 'JJ', 'NN', 'NN']\": 1,\n",
      "             \"['JJS', 'JJ', 'NN']\": 4,\n",
      "             \"['JJS', 'JJ', 'NNP', 'IN', 'DT', 'JJ']\": 1,\n",
      "             \"['JJS', 'JJ', 'NNP', 'IN', 'DT', 'NN']\": 1,\n",
      "             \"['JJS', 'JJ', 'NNP', 'NN']\": 1,\n",
      "             \"['JJS', 'JJ', 'NNP', 'NNP', 'NNP']\": 1,\n",
      "             \"['JJS', 'JJ', 'NNP', 'NNP']\": 1,\n",
      "             \"['JJS', 'JJ', 'NNS']\": 1,\n",
      "             \"['JJS', 'NN', 'IN', 'DT', 'JJ']\": 2,\n",
      "             \"['JJS', 'NN', 'IN', 'DT', 'NN']\": 1,\n",
      "             \"['JJS', 'NN', 'NN', 'NN']\": 1,\n",
      "             \"['JJS', 'NN', 'NN', 'NNP']\": 1,\n",
      "             \"['JJS', 'NN', 'NN', 'VBD']\": 1,\n",
      "             \"['JJS', 'NN', 'NN']\": 10,\n",
      "             \"['JJS', 'NN', 'NNP', 'IN', 'NNP', 'NNP']\": 2,\n",
      "             \"['JJS', 'NN', 'NNP', 'NNP', 'CC', 'NNP']\": 2,\n",
      "             \"['JJS', 'NN', 'NNP', 'NNP', 'IN', 'NNP', 'NNP']\": 1,\n",
      "             \"['JJS', 'NN', 'NNP', 'NNP', 'NNP']\": 2,\n",
      "             \"['JJS', 'NN', 'NNP', 'NNP']\": 2,\n",
      "             \"['JJS', 'NN', 'NNS']\": 1,\n",
      "             \"['JJS', 'NN', 'VBG']\": 3,\n",
      "             \"['JJS', 'NN']\": 4,\n",
      "             \"['JJS', 'NNP', 'CC', 'NNP', 'NNP', 'NNP', 'NN']\": 1,\n",
      "             \"['JJS', 'NNP', 'NNP', 'IN', 'DT', 'JJ']\": 1,\n",
      "             \"['JJS', 'NNP', 'NNP', 'IN', 'DT', 'NN']\": 1,\n",
      "             \"['JJS', 'NNP', 'NNP', 'NNP', 'NNP', 'NN']\": 1,\n",
      "             \"['JJS', 'NNP', 'NNP', 'NNP']\": 2,\n",
      "             \"['JJS', 'NNP', 'NNP']\": 1,\n",
      "             \"['JJS', 'NNS']\": 1,\n",
      "             \"['JJS', 'VBG', 'NN']\": 2,\n",
      "             \"['JJS', 'VBG', 'NNP', 'IN', 'DT', 'JJ']\": 1,\n",
      "             \"['JJS', 'VBG', 'NNP', 'IN', 'DT', 'NN']\": 1,\n",
      "             \"['JJS', 'VBG', 'NNP', 'NNP', 'NN']\": 2,\n",
      "             \"['JJS', 'VBG', 'NNP', 'NNP', 'NNP', 'CC', 'NNP', 'NNP']\": 2,\n",
      "             \"['NN', 'IN', 'DT', 'NNP', 'NNP', 'NNP']\": 1,\n",
      "             \"['NN', 'IN', 'DT', 'NNP', 'NNP']\": 1,\n",
      "             \"['NNP', 'JJ', 'NNP', 'NNP', 'NNP', 'VBG', 'NNP']\": 1,\n",
      "             \"['NNP', 'NN']\": 3,\n",
      "             \"['NNP', 'NNP', 'CC', 'NNP']\": 1,\n",
      "             \"['NNP', 'NNP', 'IN', 'DT', 'JJ']\": 1,\n",
      "             \"['NNP', 'NNP', 'IN', 'DT', 'NN']\": 1,\n",
      "             \"['NNP', 'NNP', 'NN']\": 2,\n",
      "             \"['NNP', 'NNP', 'NNP', 'CC', 'NNP', 'NNP']\": 2,\n",
      "             \"['NNP', 'NNP', 'NNP', 'IN', 'DT', 'JJ']\": 1,\n",
      "             \"['NNP', 'NNP', 'NNP', 'IN', 'DT', 'NN']\": 1,\n",
      "             \"['NNP', 'NNP', 'NNP', 'IN', 'NNP', 'IN', 'NNP']\": 1,\n",
      "             \"['NNP', 'NNP', 'NNP', 'NN']\": 1,\n",
      "             \"['NNP', 'NNP', 'NNP', 'NNP', 'CC', 'NNP', 'NNP']\": 1,\n",
      "             \"['NNP', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', 'IN', 'NNP', 'NNS']\": 1,\n",
      "             \"['NNP', 'NNP', 'NNP', 'NNP', 'NN']\": 2,\n",
      "             \"['NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'CC', 'NNP']\": 4,\n",
      "             \"['NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'VBG']\": 1,\n",
      "             \"['NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP']\": 1,\n",
      "             \"['NNP', 'NNP', 'NNP', 'NNP', 'NNP']\": 10,\n",
      "             \"['NNP', 'NNP', 'NNP', 'NNP', 'RB', 'VBG', 'NNS', 'CC', 'NNS']\": 1,\n",
      "             \"['NNP', 'NNP', 'NNP', 'NNP']\": 25,\n",
      "             \"['NNP', 'NNP', 'NNP']\": 13,\n",
      "             \"['NNP', 'NNP', 'VBG']\": 1,\n",
      "             \"['NNP', 'NNP', 'VBZ', 'NNP']\": 1,\n",
      "             \"['NNP', 'NNP']\": 2,\n",
      "             \"['NNP', 'NNPS', 'CC', 'NNP', 'NNP']\": 1,\n",
      "             \"['NNP', 'VBD', 'NNP']\": 1,\n",
      "             \"['RBS', 'JJ', 'NNP', 'NNP', 'NNP']\": 1,\n",
      "             \"['RBS', 'JJ', 'NNP', 'NNP']\": 2,\n",
      "             \"['RBS', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'IN', 'DT', 'JJ']\": 2,\n",
      "             \"['RBS', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'IN', 'DT', 'NN']\": 2,\n",
      "             \"['RBS', 'NN', 'IN', 'DT', 'VBG', 'NN', 'IN', 'DT', 'JJ']\": 2,\n",
      "             \"['RBS', 'NN', 'IN', 'DT', 'VBG', 'NN', 'IN', 'DT', 'NN']\": 2,\n",
      "             \"['RBS', 'NNP', 'NNP', 'CC', 'NNP', 'NNP']\": 1,\n",
      "             \"['RBS', 'NNP', 'NNP', 'CC', 'NNS']\": 1,\n",
      "             \"['RBS', 'NNP', 'NNP', 'NNP', 'NNP']\": 1,\n",
      "             \"['RBS', 'NNP', 'NNP', 'NNP']\": 1,\n",
      "             \"['VBG', 'JJ', 'NN']\": 1,\n",
      "             \"['VBG', 'NNP', 'NNP', 'IN', 'DT', 'JJ', 'NNP', 'CC', 'NNP']\": 2,\n",
      "             \"['VBG', 'NNP', 'NNP', 'IN', 'DT', 'NNP', 'NNP']\": 4,\n",
      "             \"['VBG', 'NNP', 'NNP', 'NNP']\": 2,\n",
      "             \"['VBG', 'NNP', 'NNP']\": 4,\n",
      "             \"['VBG', 'VBG', 'IN', 'DT', 'JJ', 'NNP', 'NNP', 'CC', 'NNP', 'NNP']\": 2,\n",
      "             \"['VBG', 'VBG', 'IN', 'DT', 'NNP', 'NNP']\": 6,\n",
      "             \"['VBG', 'VBG', 'NNP', 'IN', 'DT', 'JJ', 'NNP', 'CC', 'NNP']\": 2,\n",
      "             \"['VBG', 'VBG', 'NNP', 'IN', 'DT', 'NNP', 'NNP']\": 4})\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(award_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(award_dict.keys())) ## Represents the number of disctinct patters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex notes\n",
    "\n",
    "#+ = match 1 or more\n",
    "#? = match 0 or 1 repetitions.\n",
    "#* = match 0 or MORE repetitionS\n",
    "#. = Any character except a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern Group 0 \n",
    "\"\"\"\n",
    "{\"['JJ', 'NN']\": 1,\n",
    " \"['JJS', 'JJ', 'NN', 'NN']\": 1,\n",
    " \"['JJS', 'JJ', 'NN']\": 4,\n",
    " \"['JJS', 'JJ', 'NNP', 'IN', 'DT', 'JJ']\": 1,\n",
    " \"['JJS', 'JJ', 'NNP', 'IN', 'DT', 'NN']\": 1,\n",
    " \"['JJS', 'JJ', 'NNP', 'NN']\": 1,\n",
    " \"['JJS', 'JJ', 'NNP', 'NNP', 'NNP']\": 1,\n",
    " \"['JJS', 'JJ', 'NNP', 'NNP']\": 1,\n",
    " \"['JJS', 'JJ', 'NNS']\": 1,\n",
    " \"['JJS', 'NN', 'IN', 'DT', 'JJ']\": 2,\n",
    " \"['JJS', 'NN', 'IN', 'DT', 'NN']\": 1,\n",
    " \"['JJS', 'NN', 'NN', 'NN']\": 1,\n",
    " \"['JJS', 'NN', 'NN', 'NNP']\": 1,\n",
    " \"['JJS', 'NN', 'NN', 'VBD']\": 1,\n",
    " \"['JJS', 'NN', 'NN']\": 10,\n",
    " \"['JJS', 'NN', 'NNP', 'IN', 'NNP', 'NNP']\": 2,\n",
    " \"['JJS', 'NN', 'NNP', 'NNP', 'CC', 'NNP']\": 2,\n",
    " \"['JJS', 'NN', 'NNP', 'NNP', 'IN', 'NNP', 'NNP']\": 1,\n",
    " \"['JJS', 'NN', 'NNP', 'NNP', 'NNP']\": 2,\n",
    " \"['JJS', 'NN', 'NNP', 'NNP']\": 2,\n",
    " \"['JJS', 'NN', 'NNS']\": 1,\n",
    " \"['JJS', 'NN', 'VBG']\": 3,\n",
    " \"['JJS', 'NN']\": 4,\n",
    " \"['JJS', 'NNP', 'CC', 'NNP', 'NNP', 'NNP', 'NN']\": 1,\n",
    " \"['JJS', 'NNP', 'NNP', 'IN', 'DT', 'JJ']\": 1,\n",
    " \"['JJS', 'NNP', 'NNP', 'IN', 'DT', 'NN']\": 1,\n",
    " \"['JJS', 'NNP', 'NNP', 'NNP', 'NNP', 'NN']\": 1,\n",
    " \"['JJS', 'NNP', 'NNP', 'NNP']\": 2,\n",
    " \"['JJS', 'NNP', 'NNP']\": 1,\n",
    " \"['JJS', 'NNS']\": 1,\n",
    " \"['JJS', 'VBG', 'NN']\": 2,\n",
    " \"['JJS', 'VBG', 'NNP', 'IN', 'DT', 'JJ']\": 1,\n",
    " \"['JJS', 'VBG', 'NNP', 'IN', 'DT', 'NN']\": 1,\n",
    " \"['JJS', 'VBG', 'NNP', 'NNP', 'NN']\": 2,\n",
    " \"['JJS', 'VBG', 'NNP', 'NNP', 'NNP', 'CC', 'NNP', 'NNP']\": 2,\n",
    "\"\"\"\n",
    "\n",
    "regex_pattern_0 = \"P0: {<JJ.><NN}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern Group 1\n",
    "\n",
    "\"\"\"\n",
    "\"['NN', 'IN', 'DT', 'NNP', 'NNP', 'NNP']\": 1,\n",
    "\"['NN', 'IN', 'DT', 'NNP', 'NNP']\": 1,\n",
    "\"['NNP', 'JJ', 'NNP', 'NNP', 'NNP', 'VBG', 'NNP']\": 1,\n",
    "\"['NNP', 'NN']\": 3,\n",
    "\"['NNP', 'NNP', 'CC', 'NNP']\": 1,\n",
    "\"['NNP', 'NNP', 'IN', 'DT', 'JJ']\": 1,\n",
    "\"['NNP', 'NNP', 'IN', 'DT', 'NN']\": 1,\n",
    "\"['NNP', 'NNP', 'NN']\": 2,\n",
    "\"['NNP', 'NNP', 'NNP', 'CC', 'NNP', 'NNP']\": 2,\n",
    "\"['NNP', 'NNP', 'NNP', 'IN', 'DT', 'JJ']\": 1,\n",
    "\"['NNP', 'NNP', 'NNP', 'IN', 'DT', 'NN']\": 1,\n",
    "\"['NNP', 'NNP', 'NNP', 'IN', 'NNP', 'IN', 'NNP']\": 1,\n",
    "\"['NNP', 'NNP', 'NNP', 'NN']\": 1,\n",
    "\"['NNP', 'NNP', 'NNP', 'NNP', 'CC', 'NNP', 'NNP']\": 1,\n",
    "\"['NNP', 'NNP', 'NNP', 'NNP', 'IN', 'NNP', 'NNP', 'IN', 'NNP', 'NNS']\": 1,\n",
    "\"['NNP', 'NNP', 'NNP', 'NNP', 'NN']\": 2,\n",
    "\"['NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'CC', 'NNP']\": 4,\n",
    "\"['NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'VBG']\": 1,\n",
    "\"['NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP']\": 1,\n",
    "\"['NNP', 'NNP', 'NNP', 'NNP', 'NNP']\": 10,\n",
    "\"['NNP', 'NNP', 'NNP', 'NNP', 'RB', 'VBG', 'NNS', 'CC', 'NNS']\": 1,\n",
    "\"['NNP', 'NNP', 'NNP', 'NNP']\": 25,\n",
    "\"['NNP', 'NNP', 'NNP']\": 13,\n",
    "\"['NNP', 'NNP', 'VBG']\": 1,\n",
    "\"['NNP', 'NNP', 'VBZ', 'NNP']\": 1,\n",
    "\"['NNP', 'NNP']\": 2,\n",
    "\"['NNP', 'NNPS', 'CC', 'NNP', 'NNP']\": 1,\n",
    "\"['NNP', 'VBD', 'NNP']\": 1\n",
    "\"\"\"\n",
    "\n",
    "regex_pattern_1 = \"P1: {<JJS><JJ|NN><NN><NN|CC><NN|CC>*<NN|JJ>*<VBN>*}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern Group 2\n",
    "\n",
    "\"\"\" \"['RBS', 'JJ', 'NNP', 'NNP', 'NNP']\": 1,\n",
    " \"['RBS', 'JJ', 'NNP', 'NNP']\": 2,\n",
    " \"['RBS', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'IN', 'DT', 'JJ']\": 2,\n",
    " \"['RBS', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'IN', 'DT', 'NN']\": 2,\n",
    " \"['RBS', 'NN', 'IN', 'DT', 'VBG', 'NN', 'IN', 'DT', 'JJ']\": 2,\n",
    " \"['RBS', 'NN', 'IN', 'DT', 'VBG', 'NN', 'IN', 'DT', 'NN']\": 2,\n",
    " \"['RBS', 'NNP', 'NNP', 'CC', 'NNP', 'NNP']\": 1,\n",
    " \"['RBS', 'NNP', 'NNP', 'CC', 'NNS']\": 1,\n",
    " \"['RBS', 'NNP', 'NNP', 'NNP', 'NNP']\": 1,\n",
    " \"['RBS', 'NNP', 'NNP', 'NNP']\": 1,\"\"\"\n",
    "\n",
    "\n",
    "regex_pattern_2 = \"P2: {<RBS><NN><IN><DT><NN><IN><DT><JJ|NN><NN><CC|IN|NN><NN|DT|CC>*<NN|JJ>*<VBN|NN>*<IN|NN>*<NN|CC>*}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern Group 3\n",
    "\n",
    "\"\"\" \"['RBS', 'JJ', 'NNP', 'NNP', 'NNP']\": 1,\n",
    " \"['RBS', 'JJ', 'NNP', 'NNP']\": 2,\n",
    " \"['RBS', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'IN', 'DT', 'JJ']\": 2,\n",
    " \"['RBS', 'NN', 'IN', 'DT', 'NNP', 'NNP', 'IN', 'DT', 'NN']\": 2,\n",
    " \"['RBS', 'NN', 'IN', 'DT', 'VBG', 'NN', 'IN', 'DT', 'JJ']\": 2,\n",
    " \"['RBS', 'NN', 'IN', 'DT', 'VBG', 'NN', 'IN', 'DT', 'NN']\": 2,\n",
    " \"['RBS', 'NNP', 'NNP', 'CC', 'NNP', 'NNP']\": 1,\n",
    " \"['RBS', 'NNP', 'NNP', 'CC', 'NNS']\": 1,\n",
    " \"['RBS', 'NNP', 'NNP', 'NNP', 'NNP']\": 1,\n",
    " \"['RBS', 'NNP', 'NNP', 'NNP']\": 1,\"\"\"\n",
    "\n",
    "\n",
    "regex_pattern_3 = \"P3: {}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTweets(tweet):\n",
    "    tt = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=True)\n",
    "\n",
    "    punctuation = list(string.punctuation)\n",
    "    \n",
    "    # strip stopwords, punctuation, url components \n",
    "    stop = stopwords.words('english') + punctuation + ['t.co', 'http', 'https', '...', '..', ':\\\\', 'RT', '#']\n",
    "\n",
    "    strip_nums = re.sub(\"\\d+\", \"\", tweet)\n",
    "    tokenized = tt.tokenize(strip_nums)\n",
    "    terms_stop = [term for term in tokenized if term not in stop]\n",
    "    cleaned = [term for term in terms_stop]\n",
    "    cleaned = ' '.join(cleaned)\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_awards(text):\n",
    "    \n",
    "    text = re.sub(\"(\\s)#\\w+\",\"\",text)    # strips away all hashtags \n",
    "    text = re.sub(\"[^a-zA-Z ]\", '',text) # removes all punctuation but keeps whitespace for tokenization\n",
    "    text = text.lower()                  # makes string lowercase\n",
    "     \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tags(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_search(tags,chunk_gram,label):\n",
    "    potentials = \"No Chunk\"\n",
    "    chunk_parser = nltk.RegexpParser(chunk_gram)\n",
    "    chunked = chunk_parser.parse(tags)\n",
    "    for subtree in chunked.subtrees():\n",
    "        if subtree.label() == label: \n",
    "            potentials = ' '.join(untag(subtree))\n",
    "\n",
    "    return potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df,label):\n",
    "    \n",
    "    data = df.loc[df[label] != \"No Chunk\"]\n",
    "    data.drop(data.columns.difference([label]), 1, inplace=True)\n",
    "    single_list = list(data[label])\n",
    "    freq = FreqDist(single_list)\n",
    "    \n",
    "    return data, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_test(dic,freq):\n",
    "    \n",
    "    test = []\n",
    "    \n",
    "    for key in dic.keys():\n",
    "        if key in freq:\n",
    "            test.append([key,freq[key]])\n",
    "        else:\n",
    "            test.append([key,\"Not found\"])\n",
    "        \n",
    "    print(*test,sep='\\n')   \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13['text'] = df_13['text'].apply(lambda x:  clean_awards(x))\n",
    "df_a = df_13[df_13['text'].str.contains(\"best\")]\n",
    "df_a['tags'] = df_a['text'].apply(lambda x: find_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_a['chunks_0'] = df_a['tags'].apply(lambda x: pos_search(x,regex_pattern_0,\"P0\"))\n",
    "df_a['chunks_1'] = df_a['tags'].apply(lambda x: pos_search(x,regex_pattern_1,\"P1\"))\n",
    "df_a['chunks_2'] = df_a['tags'].apply(lambda x: pos_search(x,regex_pattern_2,\"P2\"))\n",
    "\n",
    "data_0, freq_0 = filter_df(df_a,\"chunks_0\")\n",
    "data_1, freq_1 = filter_df(df_a,\"chunks_1\")\n",
    "data_2, freq_2 = filter_df(df_a,\"chunks_2\")\n",
    "\n",
    "freq = freq_0 + freq_1 + freq_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# specific test bloc \n",
    "\n",
    "regex_pattern_test = \"test: {<RBS><NN><IN><DT><NN><IN><DT><NN><NN><NN><CC><JJ>}\"\n",
    "\n",
    "df_a['test'] = df_a['tags'].apply(lambda x: pos_search(x,regex_pattern_test,\"test\"))\n",
    "\n",
    "data_test, freq_test = filter_df(df_a,\"test\")\n",
    "\n",
    "print('best performance by an actress in a television series comedy or musical' in freq_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cecil b demille award', 'Not found']\n",
      "['best motion picture drama', 272]\n",
      "['best performance by an actress in a motion picture drama', 1]\n",
      "['best performance by an actor in a motion picture drama', 1]\n",
      "['best motion picture comedy or musical', 345]\n",
      "['best performance by an actress in a motion picture comedy or musical', 'Not found']\n",
      "['best performance by an actor in a motion picture comedy or musical', 1]\n",
      "['best animated feature film', 48]\n",
      "['best foreign language film', 36]\n",
      "['best performance by an actress in a supporting role in a motion picture', 2]\n",
      "['best performance by an actor in a supporting role in a motion picture', 3]\n",
      "['best director motion picture', 77]\n",
      "['best screenplay motion picture', 25]\n",
      "['best original score motion picture', 25]\n",
      "['best original song motion picture', 20]\n",
      "['best television series drama', 5]\n",
      "['best performance by an actress in a television series drama', 1]\n",
      "['best performance by an actor in a television series drama', 'Not found']\n",
      "['best television series comedy or musical', 72]\n",
      "['best performance by an actress in a television series comedy or musical', 'Not found']\n",
      "['best performance by an actor in a television series comedy or musical', 'Not found']\n",
      "['best mini series or motion picture made for television', 'Not found']\n",
      "['best performance by an actress in a mini series or motion picture made for television', 'Not found']\n",
      "['best performance by an actor in a mini series or motion picture made for television', 'Not found']\n",
      "['best performance by an actress in a supporting role in a series mini series or motion picture made for television', 'Not found']\n",
      "['best performance by an actor in a supporting role in a series mini series or motion picture made for television', 'Not found']\n"
     ]
    }
   ],
   "source": [
    "test = simple_test(award_dict,freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_string = ' '.join(map(str, list(df_13['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best performance by an actress in a motion picture comedy or musical\n",
      "best performance by an actress in a television series drama\n",
      "best performance by an actor in a television series drama\n",
      "best performance by an actress in a television series comedy or musical\n",
      "best performance by an actor in a television series comedy or musical\n",
      "best mini series or motion picture made for television\n",
      "best performance by an actress in a mini series or motion picture made for television\n",
      "best performance by an actor in a mini series or motion picture made for television\n",
      "best performance by an actress in a supporting role in a series mini series or motion picture made for television\n",
      "best performance by an actor in a supporting role in a series mini series or motion picture made for television\n"
     ]
    }
   ],
   "source": [
    "for award in award_dict.keys():\n",
    "    if (award not in single_string): print(award)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
