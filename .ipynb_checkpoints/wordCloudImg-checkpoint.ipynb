{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data13 = pd.read_json('../gg2013.json')\n",
    "data15 = pd.read_json('../gg2015.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_awards(text):\n",
    "    # Cleans individual tweet\n",
    "    remove_terms = ['#goldenglobes', 'golden globes', '#goldenglobe', 'golden globe', 'goldenglobes', 'goldenglobe', 'rt', 'golden', 'globe', 'globes']\n",
    "    text = re.sub(\"(\\s)#\\w+\",\"\",text)    # strips away all hashtags\n",
    "    text = re.sub(\"RT\",\"\",text)          # removes retweet\n",
    "    text = re.sub(\"[^a-zA-Z ]\", '',text) # removes all punctuation but keeps whitespace for tokenization\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = \" \".join([term for term in text if term not in remove_terms]) #remove stop words\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = np.array(Image.open(requests.get('https://cdn2.lamag.com/wp-content/uploads/sites/6/2016/01/Globe.jpg', stream=True).raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "sentences13 = []\n",
    "for each in range(0,len(data13['text'])):\n",
    "    sentences13.append(data13['text'][each])\n",
    "sentences15 = []\n",
    "for each in range(0,len(data15['text'])):\n",
    "    sentences15.append(data15['text'][each])\n",
    "# sentences18 = []\n",
    "# for each in range(0,len(data18['text'])):\n",
    "#     sentences18.append(data18['text'][each])\n",
    "# sentences19 = []\n",
    "# for each in range(0,len(data19['text'])):\n",
    "#     sentences19.append(data19['text'][each])\n",
    "\n",
    "def wordcloud13(text):\n",
    "    wordcloud = WordCloud(font_path='/Library/Fonts/Verdana.ttf',\n",
    "                          background_color='white',\n",
    "                          width = 2000, height = 2000,\n",
    "#                           min_font_size = 40,\n",
    "#                           max_font_size = 200,\n",
    "                          stopwords = stopwords\n",
    "                          ).generate(text).to_file('wordcloud-13.png')\n",
    "    plt.figure(figsize = (10, 10), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "    plt.show()\n",
    "def wordcloud15(text):\n",
    "    wordcloud = WordCloud(font_path='/Library/Fonts/Verdana.ttf',\n",
    "                          background_color='white',\n",
    "                          width = 2000, height = 2000,\n",
    "#                           min_font_size = 40,\n",
    "#                           max_font_size = 200,\n",
    "                          stopwords = stopwords\n",
    "                          ).generate(text).to_file('wordcloud-15.png')\n",
    "    plt.figure(figsize = (10, 10), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "    plt.show()\n",
    "def wordcloud18(text):\n",
    "    wordcloud = WordCloud(font_path='/Library/Fonts/Verdana.ttf',\n",
    "                          background_color='white',\n",
    "                          width = 2000, height = 2000,\n",
    "#                           min_font_size = 40,\n",
    "#                           max_font_size = 200,\n",
    "                          stopwords = stopwords\n",
    "                          ).generate(text).to_file('wordcloud-18.png')\n",
    "    plt.figure(figsize = (10, 10), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "    plt.show()\n",
    "def wordcloud19(text):\n",
    "    wordcloud = WordCloud(font_path='/Library/Fonts/Verdana.ttf',\n",
    "                          background_color='white',\n",
    "                          width = 2000, height = 2000,\n",
    "#                           min_font_size = 40,\n",
    "#                           max_font_size = 200,\n",
    "                          stopwords = stopwords\n",
    "                          ).generate(text).to_file('wordcloud-19.png')\n",
    "    plt.figure(figsize = (10, 10), facecolor=None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "    plt.show()\n",
    "    \n",
    "# generate_wordcloud(text)\n",
    "\n",
    "# sentences\n",
    "\n",
    "textblob13 = '-'.join(sentences13)\n",
    "clean13 = clean_awards(textblob13)\n",
    "wordcloud13(clean13)\n",
    "\n",
    "textblob15 = '-'.join(sentences15)\n",
    "clean15 = clean_awards(textblob15)\n",
    "wordcloud15(clean15)\n",
    "\n",
    "# textblob18 = '-'.join(sentences18)\n",
    "# clean18 = clean_awards(textblob18)\n",
    "# wordcloud18(clean18)\n",
    "\n",
    "# textblob19 = '-'.join(sentences19)\n",
    "# clean19 = clean_awards(textblob19)\n",
    "# wordcloud19(clean19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
