{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re \n",
    "\n",
    "import nltk;\n",
    "from nltk.collocations import *;\n",
    "from nltk.tokenize import word_tokenize;\n",
    "from nltk.corpus import stopwords;\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/keithpallo/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13 = pd.read_json(\"gg2013.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13 = pd.DataFrame(df_13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFFICIAL_AWARDS = ['cecil b. demille award', \n",
    "'best motion picture - drama', \n",
    "'best performance by an actress in a motion picture - drama', \n",
    "'best performance by an actor in a motion picture - drama', \n",
    "'best motion picture - comedy or musical', \n",
    " 'best performance by an actress in a motion picture - comedy or musical', \n",
    " 'best performance by an actor in a motion picture - comedy or musical', \n",
    " 'best animated feature film', 'best foreign language film', \n",
    " 'best performance by an actress in a supporting role in a motion picture', \n",
    " 'best performance by an actor in a supporting role in a motion picture', \n",
    " 'best director - motion picture', 'best screenplay - motion picture', \n",
    " 'best original score - motion picture', 'best original song - motion picture', \n",
    " 'best television series - drama', 'best performance by an actress in a television series - drama', \n",
    " 'best performance by an actor in a television series - drama', 'best television series - comedy or musical', \n",
    " 'best performance by an actress in a television series - comedy or musical', \n",
    " 'best performance by an actor in a television series - comedy or musical', \n",
    " 'best mini-series or motion picture made for television', \n",
    " 'best performance by an actress in a mini-series or motion picture made for television', \n",
    " 'best performance by an actor in a mini-series or motion picture made for television', \n",
    " 'best performance by an actress in a supporting role in a series, mini-series or motion picture made for television',\n",
    " 'best performance by an actor in a supporting role in a series, mini-series or motion picture made for television']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_awards = [re.sub(\"[^a-zA-Z0-9]+\", ' ',i) for i in OFFICIAL_AWARDS];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_structure = []\n",
    "\n",
    "for sentence in clean_awards:\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    tagged = nltk.pos_tag(tokenized_text)\n",
    "    pos_structure.append([i[1] for i in tagged])\n",
    "\n",
    "for i in range(0,len(clean_awards)):\n",
    "    pos_structure[i].append(clean_awards[i])\n",
    "    \n",
    "award_dict = {}\n",
    "\n",
    "for award in pos_structure:\n",
    "    award_dict[award[-1]] = award[:-1]\n",
    "    \n",
    "pos_structure.sort()\n",
    "# print(*pos_structure,sep='\\n')\n",
    "\n",
    "# print(award_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTweets(tweet):\n",
    "    tt = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=True)\n",
    "\n",
    "    punctuation = list(string.punctuation)\n",
    "    \n",
    "    # strip stopwords, punctuation, url components \n",
    "    stop = stopwords.words('english') + punctuation + ['t.co', 'http', 'https', '...', '..', ':\\\\', 'RT', '#']\n",
    "\n",
    "    strip_nums = re.sub(\"\\d+\", \"\", tweet)\n",
    "    tokenized = tt.tokenize(strip_nums)\n",
    "    terms_stop = [term for term in tokenized if term not in stop]\n",
    "    cleaned = [term for term in terms_stop]\n",
    "    cleaned = ' '.join(cleaned)\n",
    "    \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_awards(text):\n",
    "    \n",
    "    text = re.sub(\"(\\s)#\\w+\",\"\",text)    # strips away all hashtags \n",
    "    text = re.sub(\"[^a-zA-Z ]\", '',text) # removes all punctuation but keeps whitespace for tokenization\n",
    "    text = text.lower()                  # makes string lowercase\n",
    "     \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_entity(text):\n",
    "    text = re.sub(\"(\\s)#\\w+\",\"\",text)    # strips away all hashtags \n",
    "    text = re.sub(\"[^a-zA-Z ]\", '',text) # removes all punctuation but keeps whitespace for tokenization\n",
    "     \n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tags(tweet):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_search(tags,chunk_gram,label):\n",
    "    potentials = \"No Chunk\"\n",
    "    chunk_parser = nltk.RegexpParser(chunk_gram)\n",
    "    chunked = chunk_parser.parse(tags)\n",
    "    for subtree in chunked.subtrees():\n",
    "        if subtree.label() == label: \n",
    "            potentials = ' '.join(untag(subtree))\n",
    "\n",
    "    return potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ne_search(tags):\n",
    "    potentials = \"No Entity\"\n",
    "    namedEnt = nltk.ne_chunk(tags)\n",
    "    \n",
    "    for subtree in namedEnt.subtrees():\n",
    "        if subtree.label() == label: \n",
    "            namedEnt = ' '.join(untag(subtree))\n",
    "\n",
    "    return namedEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ne_search_spacy(tweet):\n",
    "    doc = nlp(tweet)\n",
    "    ents = list(doc.ents)\n",
    "    if len(ents) > 0:\n",
    "        return [str((X.text, X.label_)) for X in doc.ents if X.label_ != \"PERSON\"]\n",
    "    else:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_spacy(df,label):\n",
    "    data = df.loc[df[label] != \"N/A\"]\n",
    "    data.drop(data.columns.difference([label]), 1, inplace=True)\n",
    "    single_list = list(data[label])\n",
    "    single_list = [item for sublist in single_list for item in sublist]\n",
    "    \n",
    "    freq = FreqDist(single_list)\n",
    "\n",
    "    \n",
    "    return data, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_test(dic,freq):\n",
    "    \n",
    "    test = []\n",
    "    \n",
    "    for key in dic.keys():\n",
    "        if key in freq:\n",
    "            test.append([key,freq[key]])\n",
    "        else:\n",
    "            test.append([key,\"Not found\"])\n",
    "        \n",
    "    print(*test,sep='\\n')   \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_13['text'] = df_13['text'].apply(lambda x:  clean_entity(x))\n",
    "df_e = df_13[df_13['text'].str.contains(\"best\")]\n",
    "df_e['tags'] = df_e['text'].apply(lambda x: find_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/keithpallo/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/keithpallo/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_e['entity'] = df_e['text'].apply(lambda x: ne_search_spacy(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, freq = filter_spacy(df_e,\"entity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"('RT', 'ORG')\", 754),\n",
       " (\"(' ', 'NORP')\", 257),\n",
       " (\"('RT', 'GPE')\", 215),\n",
       " (\"('Homeland', 'GPE')\", 136),\n",
       " (\"('JODIE FOSTER', 'PRODUCT')\", 119),\n",
       " (\"('RT PerezHilton', 'ORG')\", 117),\n",
       " (\"('Lincoln', 'ORG')\", 107),\n",
       " (\"('Adele', 'ORG')\", 103),\n",
       " (\"('Tina', 'GPE')\", 100),\n",
       " (\"('Golden Globe', 'ORG')\", 99),\n",
       " (\"('one', 'CARDINAL')\", 89),\n",
       " (\"('Les Miserables', 'ORG')\", 87),\n",
       " (\"('tonight', 'TIME')\", 77),\n",
       " (\"('httptcoUYIbrCA', 'CARDINAL')\", 74),\n",
       " (\"('miles', 'CARDINAL')\", 69),\n",
       " (\"('the night', 'TIME')\", 58),\n",
       " (\"('the Golden Globes', 'FAC')\", 50),\n",
       " (\"('Golden Globes  ', 'ORG')\", 48),\n",
       " (\"('OfficialAdele', 'ORG')\", 46),\n",
       " (\"('Miserables', 'ORG')\", 45),\n",
       " (\"('RT AP', 'ORG')\", 44),\n",
       " (\"('Academy', 'ORG')\", 38),\n",
       " (\"('girlsHBO', 'NORP')\", 38),\n",
       " (\"('the year', 'DATE')\", 37),\n",
       " (\"('RT HuffingtonPost', 'ORG')\", 32),\n",
       " (\"('first', 'ORDINAL')\", 31),\n",
       " (\"('Django', 'ORG')\", 30),\n",
       " (\"('USA TODAY', 'ORG')\", 30),\n",
       " (\"('Oscar', 'WORK_OF_ART')\", 30),\n",
       " (\"('RT EW Tina Fey', 'ORG')\", 30),\n",
       " (\"('Golden Globes DayLewis Chastain', 'ORG')\", 29),\n",
       " (\"('RT VEVO Congrats', 'ORG')\", 28),\n",
       " (\"('Amour', 'NORP')\", 28),\n",
       " (\"('Quentin Tarantino', 'ORG')\", 26),\n",
       " (\"('Golden Globes', 'GPE')\", 25),\n",
       " (\"('Anne Hathaway', 'FAC')\", 25),\n",
       " (\"('RT HBO Congratulations', 'ORG')\", 24),\n",
       " (\"('the Golden Globe', 'ORG')\", 24),\n",
       " (\"('Zero', 'CARDINAL')\", 24),\n",
       " (\"('Django', 'GPE')\", 23),\n",
       " (\"('GoldenGlobes', 'ORG')\", 23),\n",
       " (\"('RT VanityFair', 'PRODUCT')\", 22),\n",
       " (\"('RT HuffingtonPost Homeland', 'ORG')\", 21),\n",
       " (\"('RT BreakingNews Les', 'ORG')\", 21),\n",
       " (\"('RT HuffingtonPost Daniel DayLewis', 'ORG')\", 21),\n",
       " (\"('RT HuffingtonPost Christoph Waltz', 'ORG')\", 20),\n",
       " (\"('the Golden Globes more', 'FAC')\", 20),\n",
       " (\"('RT VanityFair Congratulations', 'ORG')\", 19),\n",
       " (\"('RT TVGuide', 'ORG')\", 19),\n",
       " (\"('RT HBO Cheers', 'ORG')\", 19),\n",
       " (\"('One', 'CARDINAL')\", 18),\n",
       " (\"('this year', 'DATE')\", 18),\n",
       " (\"('Les Miserables', 'EVENT')\", 18),\n",
       " (\"('Smith', 'ORG')\", 18),\n",
       " (\"('Golden Globes Adele', 'GPE')\", 18),\n",
       " (\"('Eagles', 'ORG')\", 18),\n",
       " (\"(' VW', 'ORG')\", 18),\n",
       " (\"(' ', 'ORG')\", 17),\n",
       " (\"('Argo  ', 'GPE')\", 17),\n",
       " (\"('RT RobertVerdi', 'ORG')\", 17),\n",
       " (\"('RT RallisP', 'ORG')\", 16),\n",
       " (\"('RT AudrinaPatridge Hahahah', 'ORG')\", 16),\n",
       " (\"('HuffingtonPost', 'ORG')\", 15),\n",
       " (\"('PerezHilton', 'ORG')\", 15),\n",
       " (\"('LenaDunham', 'ORG')\", 15),\n",
       " (\"('girlsHBO', 'ORG')\", 15),\n",
       " (\"('httptcoyoLVLF', 'CARDINAL')\", 15),\n",
       " (\"('Adeles', 'ORG')\", 14),\n",
       " (\"('two', 'CARDINAL')\", 13),\n",
       " (\"('years', 'DATE')\", 13),\n",
       " (\"('Salma Hayek', 'ORG')\", 13),\n",
       " (\"('Wiig', 'GPE')\", 13),\n",
       " (\"('RT VanityFair Girls', 'ORG')\", 13),\n",
       " (\"('Hatfields', 'ORG')\", 12),\n",
       " (\"('miniseriesTV', 'NORP')\", 12),\n",
       " (\"('San Francisco', 'GPE')\", 12),\n",
       " (\"('Dark Thirty', 'FAC')\", 12),\n",
       " (\"('SNL', 'ORG')\", 11),\n",
       " (\"('Les Miserables', 'PRODUCT')\", 11),\n",
       " (\"('Tarantino', 'ORG')\", 11),\n",
       " (\"('RT HuffingtonPost Lena Dunham', 'ORG')\", 11),\n",
       " (\"('Jodie', 'ORG')\", 11),\n",
       " (\"('AP', 'ORG')\", 10),\n",
       " (\"('RT ADuralde', 'ORG')\", 10),\n",
       " (\"('the Golden Globes', 'GPE')\", 10),\n",
       " (\"('Silver Linings Playbook', 'ORG')\", 10),\n",
       " (\"('Yemen', 'GPE')\", 10),\n",
       " (\"('RT TVWithoutPity', 'ORG')\", 10),\n",
       " (\"('RT VanityFair Daniel DayLewis', 'ORG')\", 10),\n",
       " (\"('Kudos', 'GPE')\", 9),\n",
       " (\"('The Golden Globes', 'WORK_OF_ART')\", 9),\n",
       " (\"('RT AP Christoph Waltz', 'ORG')\", 9),\n",
       " (\"('SHOHomeland', 'ORG')\", 9),\n",
       " (\"('RT popsugar Congrats', 'ORG')\", 9),\n",
       " (\"('Homeland', 'FAC')\", 9),\n",
       " (\"('Golden Globes  ', 'GPE')\", 9),\n",
       " (\"('Hollywood', 'GPE')\", 9),\n",
       " (\"(' year old', 'DATE')\", 9),\n",
       " (\"('Jodie Fosters', 'ORG')\", 9),\n",
       " (\"('RT EdwardWeeks Unofficial', 'PRODUCT')\", 9)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('RT', 'ORG'): 754, (' ', 'NORP'): 257, ('RT', 'GPE'): 215, ('Homeland', 'GPE'): 136, ('Hugh Jackman', 'PERSON'): 134, ('Amy', 'PERSON'): 132, ('Ben Affleck', 'PERSON'): 127, ('JODIE FOSTER', 'PRODUCT'): 119, ('RT PerezHilton', 'ORG'): 117, ('Lincoln', 'ORG'): 107, ...})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist(single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
